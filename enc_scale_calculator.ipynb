{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad161294",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mousakha/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/mousakha/miniconda3/envs/muldit_env/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/mousakha/miniconda3/envs/muldit_env/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from omegaconf import OmegaConf\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76cd5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunningStatsTensors(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.n = 0  # Count of data points seen so far\n",
    "        # Initialize mean and variance tensors as parameters to enable device transfer\n",
    "        self.mean = torch.nn.Parameter(torch.zeros(1))\n",
    "        self.S = torch.nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def update(self, x):\n",
    "        batch_size = x.numel()  # Get the number of elements in the new tensor\n",
    "\n",
    "        if self.n == 0:\n",
    "            # First batch initialization\n",
    "            self.mean.data = x.mean()  # Initialize the mean with the batch mean\n",
    "            # Initialize variance with the sum of squared differences from the batch mean\n",
    "            self.S.data = ((x - self.mean) ** 2).sum()\n",
    "        else:\n",
    "            # Calculate the new total number of elements\n",
    "            new_n = self.n + batch_size\n",
    "            delta = x.mean() - self.mean\n",
    "            new_mean = self.mean + delta * batch_size / new_n\n",
    "\n",
    "            # Update the variance (S) using Welford's method\n",
    "            self.S.data += ((x - self.mean)**2).sum()\n",
    "\n",
    "            # Update the running mean\n",
    "            self.mean.data = new_mean\n",
    "\n",
    "        # Update the count of elements\n",
    "        self.n += batch_size\n",
    "\n",
    "    def get_mean(self):\n",
    "        return self.mean\n",
    "    \n",
    "    def get_std(self):\n",
    "        # Unbiased estimate: divide by n - 1\n",
    "        if self.n > 1:\n",
    "            return torch.sqrt(self.S / (self.n - 1))\n",
    "        else:\n",
    "            return torch.tensor(0.0, device=self.mean.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "959fbafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_stats = RunningStatsTensors()\n",
    "running_stats2 = RunningStatsTensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76249ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = \"logs_tk/2025-05-20T16-27-30_vq_IF_dino2_e16_DLC11518833_dec/checkpoints/last.ckpt\"\n",
    "cfg = \"logs_tk/2025-05-20T16-27-30_vq_IF_dino2_e16_DLC11518833_dec/config.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b1f5b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VQLPIPSWithDiscriminator initialized with hinge loss.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mousakha/miniconda3/envs/muldit_env/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/mousakha/miniconda3/envs/muldit_env/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "[2025-06-28 13:10:02] [INFO] Loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "[2025-06-28 13:10:03] [INFO] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch14_dinov2.lvd142m)\n",
      "[2025-06-28 13:10:03] [INFO] [timm/vit_base_patch14_dinov2.lvd142m] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[2025-06-28 13:10:03] [INFO] Resized position embedding: (37, 37) to (16, 16).\n",
      "[2025-06-28 13:10:05] [INFO] Loading pretrained weights from Hugging Face hub (timm/vit_base_patch16_224.mae)\n",
      "[2025-06-28 13:10:05] [INFO] [timm/vit_base_patch16_224.mae] Safe alternative available for 'pytorch_model.bin' (as 'model.safetensors'). Loading weights using safetensors.\n",
      "[2025-06-28 13:10:05] [INFO] Resized position embedding: (14, 14) to (16, 16).\n",
      "/tmp/ipykernel_2018794/3045436711.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(ckpt)[\"state_dict\"], strict=True)\n",
      "[2025-06-28 13:10:09] [INFO] Loading dataset: train\n",
      "[2025-06-28 13:10:39] [INFO] <data.custom.MultiHDF5Dataset object at 0x7f3f2450ff10>\n",
      "[2025-06-28 13:10:39] [INFO] Loading dataset: validation\n",
      "[2025-06-28 13:10:39] [INFO] <data.custom.MultiHDF5Dataset object at 0x7f3f2450d390>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset length: 492929\n",
      "Total dataset length: 5258\n"
     ]
    }
   ],
   "source": [
    "config = OmegaConf.load(cfg)\n",
    "model = instantiate_from_config(config.model)\n",
    "\n",
    "model.load_state_dict(torch.load(ckpt)[\"state_dict\"], strict=True)\n",
    "model = model.cuda()\n",
    "_ = model.eval()\n",
    "\n",
    "\n",
    "data = instantiate_from_config(config.data)\n",
    "data.prepare_data()\n",
    "data.setup()\n",
    "train_loader = data.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d019f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating dataset statistics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 500it [02:44,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Latent mean: 0.03317122906446457, Latent std: 0.35201364755630493\n",
      "2: Latent mean: 0.013119198381900787, Latent std: 0.3533176779747009\n",
      "enc_scale: 2.840798854827881,  enc_scale_dino:2.8303141593933105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 1000it [05:03,  6.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Latent mean: 0.03351333364844322, Latent std: 0.35197195410728455\n",
      "2: Latent mean: 0.013172510080039501, Latent std: 0.3533124327659607\n",
      "enc_scale: 2.8411355018615723,  enc_scale_dino:2.8303561210632324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 1499it [07:11,  4.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Latent mean: 0.03354831784963608, Latent std: 0.3519652485847473\n",
      "2: Latent mean: 0.013123990967869759, Latent std: 0.3533129394054413\n",
      "enc_scale: 2.8411896228790283,  enc_scale_dino:2.8303520679473877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches: 1542it [07:19,  8.09it/s]"
     ]
    }
   ],
   "source": [
    "print(\"Calculating dataset statistics...\")\n",
    "\n",
    "\n",
    "for idx, batch in tqdm(enumerate(train_loader), desc=\"Processing Batches\"):\n",
    "    # Compute the statistics for the current batch\n",
    "    with torch.no_grad():\n",
    "        # Forward pass through the model\n",
    "        \n",
    "\n",
    "        x = batch # ['image']\n",
    "        # x = x.permute(0, 3, 1, 2).to(memory_format=torch.contiguous_format)\n",
    "        x = x.cuda()\n",
    "        x= x.float()\n",
    "\n",
    "\n",
    "\n",
    "        h = model.encode(x)['continuous']\n",
    "        if isinstance(h, tuple):\n",
    "            h1 = h[0]\n",
    "            h2 = h[1]\n",
    "            \n",
    "\n",
    "            h1 = h1.view(-1)\n",
    "            h2 = h2.view(-1)\n",
    "            # Update the running statistics\n",
    "            running_stats.update(h1)\n",
    "            running_stats2.update(h2)\n",
    "\n",
    "            if idx %500==0 and idx > 0:\n",
    "                mean = running_stats.get_mean()\n",
    "                std = running_stats.get_std()\n",
    "                print(f\"1: Latent mean: {mean.mean()}, Latent std: {std.mean()}\")\n",
    "                mean2 = running_stats2.get_mean()\n",
    "                std2 = running_stats2.get_std()\n",
    "                print(f\"2: Latent mean: {mean2.mean()}, Latent std: {std2.mean()}\")\n",
    "                print(f'enc_scale: {1/std.mean()},  enc_scale_dino: {1/std2.mean()}')\n",
    "        else:\n",
    "            h = h.view(-1)\n",
    "            # Update the running statistics\n",
    "            running_stats.update(h)\n",
    "\n",
    "            if idx %500==0 and idx > 0:\n",
    "                mean = running_stats.get_mean()\n",
    "                std = running_stats.get_std()\n",
    "                print(f\"Latent mean: {mean.mean()}, Latent std: {std.mean()}\")\n",
    "                print(f'enc_scale: {1/std.mean()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a58618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79cad8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "muldit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
